{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 185465 files belonging to 16 classes.\n",
      "Using 148372 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 21:02:40.785104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 21:02:40.812386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 21:02:40.812573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 21:02:40.813101: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-21 21:02:40.813483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 21:02:40.813629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 21:02:40.813761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 21:02:41.185629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 21:02:41.185798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 21:02:41.185930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 21:02:41.186055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 532 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:26:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 185465 files belonging to 16 classes.\n",
      "Using 37093 files for validation.\n"
     ]
    }
   ],
   "source": [
    "ds_train = keras.utils.image_dataset_from_directory(\n",
    "    directory = \"../data/\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=64,\n",
    "    image_size=(45, 45),\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "ds_val = keras.utils.image_dataset_from_directory(\n",
    "    directory = \"../data/\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=64,\n",
    "    image_size=(45, 45),\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "ds_test = ds_val.take(290)\n",
    "ds_val = ds_val.skip(290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 45, 45, 3), dtype=float32, numpy=\n",
       " array([[[[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]]],\n",
       " \n",
       " \n",
       "        [[[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]]],\n",
       " \n",
       " \n",
       "        [[[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]]],\n",
       " \n",
       " \n",
       "        [[[250., 250., 250.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[252., 252., 252.],\n",
       "          [253., 253., 253.],\n",
       "          [252., 252., 252.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[253., 253., 253.],\n",
       "          [255., 255., 255.],\n",
       "          [251., 251., 251.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [253., 253., 253.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [254., 254., 254.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [  1.,   1.,   1.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [254., 254., 254.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.],\n",
       "          [251., 251., 251.],\n",
       "          [255., 255., 255.]]],\n",
       " \n",
       " \n",
       "        [[[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]],\n",
       " \n",
       "         [[255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          ...,\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.],\n",
       "          [255., 255., 255.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 16), dtype=float32, numpy=\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches for testing --> tf.Tensor(290, shape=(), dtype=int64)\n",
      "Batches for validating --> tf.Tensor(290, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print('Batches for testing -->', ds_test.cardinality())\n",
    "print('Batches for validating -->', ds_val.cardinality())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(filters=32, kernel_size=5, strides=1, activation=\"relu\", input_shape=(45, 45, 3), kernel_regularizer=regularizers.l2(0.0005)),\n",
    "        layers.Conv2D(filters=32, kernel_size=5, strides=1, use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv2D(filters=64, kernel_size=3, strides=1, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0005)),\n",
    "        layers.Conv2D(filters=64, kernel_size=3, strides=1, use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(units=256, use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.Dense(units=128, use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.Dense(units=64, use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(units=16, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2319/2319 [==============================] - 21s 9ms/step - loss: 0.0428 - accuracy: 0.9877 - val_loss: 0.0635 - val_accuracy: 0.9818\n",
      "Epoch 2/30\n",
      "2319/2319 [==============================] - 21s 9ms/step - loss: 0.0408 - accuracy: 0.9884 - val_loss: 0.0804 - val_accuracy: 0.9752\n",
      "Epoch 3/30\n",
      "2319/2319 [==============================] - 21s 9ms/step - loss: 0.0396 - accuracy: 0.9886 - val_loss: 0.8721 - val_accuracy: 0.7734\n",
      "Epoch 4/30\n",
      "2319/2319 [==============================] - 21s 9ms/step - loss: 0.0381 - accuracy: 0.9888 - val_loss: 1.2991 - val_accuracy: 0.5866\n",
      "Epoch 5/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0368 - accuracy: 0.9890 - val_loss: 0.0330 - val_accuracy: 0.9912\n",
      "Epoch 6/30\n",
      "2319/2319 [==============================] - 21s 9ms/step - loss: 0.0364 - accuracy: 0.9894 - val_loss: 0.8943 - val_accuracy: 0.7443\n",
      "Epoch 7/30\n",
      "2319/2319 [==============================] - 21s 9ms/step - loss: 0.0358 - accuracy: 0.9895 - val_loss: 0.8086 - val_accuracy: 0.7475\n",
      "Epoch 8/30\n",
      "2319/2319 [==============================] - 21s 9ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 0.0271 - val_accuracy: 0.9923\n",
      "Epoch 9/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0345 - accuracy: 0.9901 - val_loss: 1.1417 - val_accuracy: 0.7425\n",
      "Epoch 10/30\n",
      "2319/2319 [==============================] - 21s 9ms/step - loss: 0.0324 - accuracy: 0.9908 - val_loss: 0.1781 - val_accuracy: 0.9464\n",
      "Epoch 11/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0333 - accuracy: 0.9903 - val_loss: 0.0346 - val_accuracy: 0.9899\n",
      "Epoch 12/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.4001 - val_accuracy: 0.8884\n",
      "Epoch 13/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.0355 - val_accuracy: 0.9900\n",
      "Epoch 14/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.2433 - val_accuracy: 0.9315\n",
      "Epoch 15/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0296 - accuracy: 0.9917 - val_loss: 0.0259 - val_accuracy: 0.9921\n",
      "Epoch 16/30\n",
      "2319/2319 [==============================] - 21s 9ms/step - loss: 0.0298 - accuracy: 0.9914 - val_loss: 0.0249 - val_accuracy: 0.9934\n",
      "Epoch 17/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.1171 - val_accuracy: 0.9633\n",
      "Epoch 18/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 0.0356 - val_accuracy: 0.9907\n",
      "Epoch 19/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0276 - accuracy: 0.9922 - val_loss: 0.0331 - val_accuracy: 0.9909\n",
      "Epoch 20/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0278 - accuracy: 0.9922 - val_loss: 0.0271 - val_accuracy: 0.9925\n",
      "Epoch 21/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 0.3822 - val_accuracy: 0.8834\n",
      "Epoch 22/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0271 - accuracy: 0.9926 - val_loss: 0.4660 - val_accuracy: 0.8633\n",
      "Epoch 23/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0263 - accuracy: 0.9927 - val_loss: 0.0401 - val_accuracy: 0.9876\n",
      "Epoch 24/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 10.7269 - val_accuracy: 0.0802\n",
      "Epoch 25/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.2192 - val_accuracy: 0.9442\n",
      "Epoch 26/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0255 - accuracy: 0.9929 - val_loss: 0.0326 - val_accuracy: 0.9912\n",
      "Epoch 27/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 0.0718 - val_accuracy: 0.9801\n",
      "Epoch 28/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0244 - accuracy: 0.9935 - val_loss: 0.0565 - val_accuracy: 0.9859\n",
      "Epoch 29/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.0292 - val_accuracy: 0.9925\n",
      "Epoch 30/30\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 0.0201 - val_accuracy: 0.9955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d94253130>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=30, validation_data=ds_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02037290297448635, 0.9949892163276672]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 17:13:38.856782: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../model\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4043f920f50c1fdf9a9b8b4290230a8c58ae9e914d50003ffd089c1c19a29f7f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cvenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
